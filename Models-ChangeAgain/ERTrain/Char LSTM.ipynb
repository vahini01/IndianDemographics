{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_xep_Kdsdz_"
   },
   "source": [
    "https://github.com/prdeepakbabu/Python/blob/master/Deep%20learning%20gender/Deep%20Learning%20(RNN%20-%20LSTMs)%20Predict%20Gender%20from%20Name.ipynb From this link with different data\n",
    "\n",
    "https://github.com/mhjabreel/CharCnn_Keras/blob/master/models/char_cnn_zhang.py char CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hZ3N3Q1AsbHh"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.python.keras.layers.core import Dense, Activation, Dropout\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorflow.python.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.python.keras.layers import Dense, Embedding\n",
    "from tensorflow.python.keras.layers import LSTM\n",
    "from tensorflow.python.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../../PreProcessing/')\n",
    "\n",
    "from utils import *\n",
    "from parse_df import *\n",
    "from split_name import *\n",
    "from char_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/souvic/mounted/btp/vahini/Models/ERTrain/../../PreProcessing/parse_df.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Name'] = df['Name'].str.lower()\n",
      "/home/souvic/mounted/btp/vahini/Models/ERTrain/../../PreProcessing/parse_df.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['len']= [len(str(i)) for i in df[col]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "FEMALE    10405236\n",
      "MALE      11632598\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "er_df = getERData(\"../\")\n",
    "er_df = er_df.rename(columns = {'name':'Name', 'gender':'Gender'})\n",
    "er_df = cleanDf(er_df, 'Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "er_df = er_df.dropna(subset=['Gender'])\n",
    "er_df = er_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22037835, 9)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "er_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender  Gender\n",
       "FEMALE  FEMALE    10405236\n",
       "MALE    MALE      11632599\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "er_df.groupby('Gender')['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ((14776538, 30),(14776538, 2))  Test: ((6332842, 30),(6332842, 2))\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y = splitERData(er_df, 'Name', 'char_lstm_er_oov.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21109380"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape[0]+train_x.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(MAXLEN_NAME_CHAR_LSTM)\n",
    "x = Embedding(len(voc)+1, len(voc)+1)(inputs)\n",
    "x = LSTM(512, return_sequences=True, activation='tanh')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = LSTM(512, return_sequences=False, activation='tanh')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 30, 29)            841       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 30, 512)           1110016   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 3,211,083\n",
      "Trainable params: 3,211,083\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 8983/14777 [=================>............] - ETA: 30:43 - loss: 0.3048 - accuracy: 0.8610"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14777/14777 [==============================] - 5192s 351ms/step - loss: 0.2620 - accuracy: 0.8851 - val_loss: 0.1345 - val_accuracy: 0.9524\n",
      "Epoch 2/10\n",
      "14777/14777 [==============================] - 5153s 349ms/step - loss: 0.1306 - accuracy: 0.9544 - val_loss: 0.1252 - val_accuracy: 0.9566\n",
      "Epoch 3/10\n",
      " 2601/14777 [====>.........................] - ETA: 1:03:55 - loss: 0.1196 - accuracy: 0.9590"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13377/14777 [==========================>...] - ETA: 7:21 - loss: 0.1204 - accuracy: 0.9588"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14777/14777 [==============================] - 5148s 348ms/step - loss: 0.1204 - accuracy: 0.9588 - val_loss: 0.1224 - val_accuracy: 0.9582\n",
      "Epoch 4/10\n",
      " 7631/14777 [==============>...............] - ETA: 34:00 - loss: 0.1152 - accuracy: 0.9612"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14777/14777 [==============================] - 4714s 319ms/step - loss: 0.1155 - accuracy: 0.9610 - val_loss: 0.1203 - val_accuracy: 0.9590\n",
      "Epoch 5/10\n",
      " 2932/14777 [====>.........................] - ETA: 1:02:05 - loss: 0.1106 - accuracy: 0.9631"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13180/14777 [=========================>....] - ETA: 8:22 - loss: 0.1119 - accuracy: 0.9626"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8694/14777 [================>.............] - ETA: 31:58 - loss: 0.1087 - accuracy: 0.9639"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4160/14777 [=======>......................] - ETA: 55:54 - loss: 0.1065 - accuracy: 0.9649"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14128/14777 [===========================>..] - ETA: 4:35 - loss: 0.1075 - accuracy: 0.9644"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11853/14777 [=======================>......] - ETA: 26:43 - loss: 0.1055 - accuracy: 0.9652"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6405/14777 [============>.................] - ETA: 1:16:28 - loss: 0.1038 - accuracy: 0.9662"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14777/14777 [==============================] - 7733s 523ms/step - loss: 0.1044 - accuracy: 0.9658 - val_loss: 0.1189 - val_accuracy: 0.9600\n",
      "Epoch 10/10\n",
      " 5088/14777 [=========>....................] - ETA: 50:51 - loss: 0.1015 - accuracy: 0.9669"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14777/14777 [==============================] - 5142s 348ms/step - loss: 0.1027 - accuracy: 0.9664 - val_loss: 0.1197 - val_accuracy: 0.9599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd8578e76a0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y,batch_size=batch_size,epochs=10,validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197902/197902 [==============================] - 5228s 26ms/step - loss: 0.1197 - accuracy: 0.9599\n",
      "Test score: 0.11973106861114502\n",
      "Test accuracy: 0.9599427580833435\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(test_x, test_y)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: SavedModels/FinalSet/CharLSTM/ERModel/ERModel/assets\n"
     ]
    }
   ],
   "source": [
    "filename = \"SavedModels/FinalSet/CharLSTM/ERModel/ERModel\"\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------RESULTS-------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Male       0.96      0.97      0.96   3299170\n",
      "      Female       0.96      0.95      0.96   3033672\n",
      "\n",
      "    accuracy                           0.96   6332842\n",
      "   macro avg       0.96      0.96      0.96   6332842\n",
      "weighted avg       0.96      0.96      0.96   6332842\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(np.asarray(test_x))\n",
    "y_pred = np.argmax(pred, axis=1)\n",
    "y_true = np.argmax(test_y, axis=1)\n",
    "\n",
    "target_names = ['Male','Female']\n",
    "\n",
    "print(\"------------------RESULTS-------------------------------\")\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Input, Embedding, Activation, Flatten, Dense\n",
    "from tensorflow.python.keras.layers import Conv1D, MaxPooling1D, Dropout\n",
    "from tensorflow.python.keras.models import Model\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHAR CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(MAXLEN_NAME_CHAR_CNN)\n",
    "x = Embedding(len(voc)+1, len(voc)+1)(inputs)\n",
    "x = Conv1D(filters = 256, kernel_size = 7, activation = 'relu')(x)\n",
    "x = Flatten()(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "cnn_model = Model(inputs=inputs, outputs=predictions)\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 30, 29)            841       \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 24, 256)           52224     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 12290     \n",
      "=================================================================\n",
      "Total params: 65,355\n",
      "Trainable params: 65,355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 15:27:58.276923: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-10-28 15:28:08.443063: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2021-10-28 15:28:09.520029: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14777/14777 [==============================] - 268s 16ms/step - loss: 0.2400 - accuracy: 0.9032 - val_loss: 0.1836 - val_accuracy: 0.9324\n",
      "Epoch 2/15\n",
      "14777/14777 [==============================] - 195s 13ms/step - loss: 0.1714 - accuracy: 0.9379 - val_loss: 0.1680 - val_accuracy: 0.9398\n",
      "Epoch 3/15\n",
      "14777/14777 [==============================] - 195s 13ms/step - loss: 0.1650 - accuracy: 0.9409 - val_loss: 0.1637 - val_accuracy: 0.9414\n",
      "Epoch 4/15\n",
      "14777/14777 [==============================] - 195s 13ms/step - loss: 0.1617 - accuracy: 0.9423 - val_loss: 0.1627 - val_accuracy: 0.9422\n",
      "Epoch 5/15\n",
      "14777/14777 [==============================] - 196s 13ms/step - loss: 0.1595 - accuracy: 0.9432 - val_loss: 0.1608 - val_accuracy: 0.9426\n",
      "Epoch 6/15\n",
      "14777/14777 [==============================] - 197s 13ms/step - loss: 0.1579 - accuracy: 0.9440 - val_loss: 0.1593 - val_accuracy: 0.9434\n",
      "Epoch 7/15\n",
      "14777/14777 [==============================] - 196s 13ms/step - loss: 0.1569 - accuracy: 0.9445 - val_loss: 0.1615 - val_accuracy: 0.9425\n",
      "Epoch 8/15\n",
      "14777/14777 [==============================] - 196s 13ms/step - loss: 0.1564 - accuracy: 0.9447 - val_loss: 0.1564 - val_accuracy: 0.9449\n",
      "Epoch 9/15\n",
      "14777/14777 [==============================] - 196s 13ms/step - loss: 0.1552 - accuracy: 0.9450 - val_loss: 0.1587 - val_accuracy: 0.9441\n",
      "Epoch 10/15\n",
      "14777/14777 [==============================] - 201s 14ms/step - loss: 0.1544 - accuracy: 0.9454 - val_loss: 0.1563 - val_accuracy: 0.9446\n",
      "Epoch 11/15\n",
      "14777/14777 [==============================] - 204s 14ms/step - loss: 0.1542 - accuracy: 0.9455 - val_loss: 0.1561 - val_accuracy: 0.9448\n",
      "Epoch 12/15\n",
      "14777/14777 [==============================] - 204s 14ms/step - loss: 0.1538 - accuracy: 0.9458 - val_loss: 0.1558 - val_accuracy: 0.9451\n",
      "Epoch 13/15\n",
      "14777/14777 [==============================] - 206s 14ms/step - loss: 0.1536 - accuracy: 0.9458 - val_loss: 0.1562 - val_accuracy: 0.9446\n",
      "Epoch 14/15\n",
      "14777/14777 [==============================] - 205s 14ms/step - loss: 0.1532 - accuracy: 0.9461 - val_loss: 0.1555 - val_accuracy: 0.9454\n",
      "Epoch 15/15\n",
      "14777/14777 [==============================] - 205s 14ms/step - loss: 0.1527 - accuracy: 0.9463 - val_loss: 0.1547 - val_accuracy: 0.9456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd8048a28e0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=1000\n",
    "cnn_model.fit(train_x, train_y,batch_size=batch_size,epochs=15,validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197902/197902 [==============================] - 552s 3ms/step - loss: 0.1547 - accuracy: 0.9456\n",
      "Test score: 0.15472562611103058\n",
      "Test accuracy: 0.9456402063369751\n"
     ]
    }
   ],
   "source": [
    "score, acc = cnn_model.evaluate(test_x, test_y)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------RESULTS-------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Male       0.94      0.95      0.95   3299170\n",
      "      Female       0.95      0.94      0.94   3033672\n",
      "\n",
      "    accuracy                           0.95   6332842\n",
      "   macro avg       0.95      0.95      0.95   6332842\n",
      "weighted avg       0.95      0.95      0.95   6332842\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pred = cnn_model.predict(np.asarray(test_x))\n",
    "y_pred = np.argmax(pred, axis=1)\n",
    "y_true = np.argmax(test_y, axis=1)\n",
    "\n",
    "target_names = ['Male','Female']\n",
    "\n",
    "print(\"------------------RESULTS-------------------------------\")\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../SavedModels/FinalSet/CharCNN/ERModel/ERModel/assets\n"
     ]
    }
   ],
   "source": [
    "filename = \"../SavedModels/FinalSet/CharCNN/ERModel/ERModel\"\n",
    "cnn_model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: SavedModels/FinalSet/CharCNN/ERModel/ERModel/assets\n"
     ]
    }
   ],
   "source": [
    "filename = \"SavedModels/FinalSet/CharCNN/ERModel/ERModel\"\n",
    "cnn_model.save(filename)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": " LSTM from Github link with segregated data",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
